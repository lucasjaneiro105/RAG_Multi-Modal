![image](https://github.com/user-attachments/assets/9128bc49-4610-442c-805f-f8b35b59add9)

# RAG-MultiModal ü§ñ

Este projeto implementa um sistema de Resposta Baseada em Recupera√ß√£o (RAG - Retrieval-Augmented Generation) com suporte multimodal, utilizando Streamlit, LangChain e Docling. Ele permite o upload de diversos tipos de arquivos (PDF, DOCX, PPTX, JPG, PNG) e inicia um chatbot que analisa e responde perguntas com base no conte√∫do dos documentos enviados. 

## Vis√£o Geral ‚öôÔ∏è

RAG-MultiModal combina t√©cnicas avan√ßadas de convers√£o de documentos, divis√£o de textos e armazenamento vetorial para proporcionar respostas precisas e contextualizadas em intera√ß√µes via chat. Ao processar e converter os arquivos para um formato textual, o sistema utiliza embeddings e uma cadeia conversacional de recupera√ß√£o para manter o contexto durante toda a conversa. Dessa forma, ele √© ideal para an√°lise e interpreta√ß√£o de documentos de diferentes formatos, garantindo uma experi√™ncia interativa e multimodal.

## Caracter√≠sticas Principais

1. **Suporte a m√∫ltiplos formatos**: Permite o upload e processamento de arquivos em PDF, DOCX, PPTX, JPG e PNG.
2. **Interface interativa**: Desenvolvida com Streamlit, oferecendo upload de arquivos e chat em tempo real diretamente no navegador.
3. **Armazenamento vetorial eficiente**: Implementado com FAISS para busca por similaridade e recupera√ß√£o de informa√ß√µes.
4. **Integra√ß√£o com m√∫ltiplas APIs**: Compat√≠vel com OpenAI (para embeddings) e Groq (para modelagem conversacional) para processamento de linguagem.
5. **Conversa√ß√£o contextualizada**: Mant√©m o hist√≥rico do di√°logo e utiliza o contexto dos documentos para gerar respostas precisas.
6. **Modularidade e personaliza√ß√£o**: Facilmente adapt√°vel, permitindo ajustes nos prompts, na configura√ß√£o dos modelos e em outros par√¢metros.

## Limita√ß√µes

- A qualidade das respostas depende da clareza, tamanho e formata√ß√£o dos documentos processados.
- Algumas depend√™ncias do Docling possuem diverg√™ncias com o Streamlit, ocasionando pequenos problemas, mas nada que interfira diretamente no c√≥digo.
- Utilizar a embedding de um modelo pago (OpenAI) gera um pequeno custo.
- Por ser uma biblioteca nova e ainda em fase experimental, pode demorar para carregar arquivos dependendo do seu tamanho, podendo levar at√© minutos somente para carregar.
- O sistema apresentou certa dificuldade para fornecer informa√ß√µes a partir de imagens; entretanto, os desenvolvedores do Docling est√£o trabalhando em atualiza√ß√µes para melhorar a extra√ß√£o de dados de imagens.

## Observa√ß√µes

- Foi utilizada a embedding de um modelo pago, mas poderia ser utilizada uma do Huggingface sem problemas.
- A FAISS foi escolhida para a vector store por sua rapidez no processamento, mas outras alternativas como Chroma ou Milvus tamb√©m funcionariam perfeitamente.
- Embora seja poss√≠vel utilizar um modelo pago como o da OpenAI para a LLM, optei pelo modelo da Groq (Ollama), que apresentou respostas com melhor qualidade.
- Existem outras bibliotecas que lidam com OCR, como o pytesseract, mas na minha experi√™ncia a integra√ß√£o e a l√≥gica com o Docling foram mais simples e eficientes.
- Para arquivos pequenos e com o objetivo principal de ler textos e tabelas, o sistema supre a necessidade, considerando que √© gratuito e de f√°cil implementa√ß√£o e entendimento.

## Como Executar

1. **Clone o reposit√≥rio**:
```bash
git clone <repository-url>
cd <repository-folder>
```

2. **Instale as depend√™ncias**: Certifique-se de ter Python 3.8+ instalado.
```bash
pip install -r requirements.txt
```

3. **Configure as vari√°veis de ambiente**: Crie um arquivo .env na raiz do projeto com sua chave de API:
```bash
GROQ_API_KEY=<sua-chave-api>
```

4. **Inicie a aplica√ß√£o:**:
```bash
streamlit run Main.py
```
